{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5fcf1a8",
   "metadata": {},
   "source": [
    "# Multimodal Disaster Analysis using Social Media\n",
    "### Ronak Sharma (210108041)\n",
    "*DA 623 – Computing with Signals*  \n",
    "*Indian Institute of Technology Guwahati*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2686a2",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "In recent years, the frequency and intensity of natural disasters such as floods, earthquakes, and hurricanes have increased. Effective disaster management depends on timely and accurate information. Traditional systems using satellite images and ground sensors suffer from latency and limited coverage. Given the global penetration of social media, it can be a rich, real-time source of multimodal data (text, images, videos, location). This project explores how such multimodal data can enhance disaster response systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44bfc8",
   "metadata": {},
   "source": [
    "## Connection to Past and Current Work in Multimodal Learning\n",
    "Multimodal learning integrates information from different types of data: text, images, audio, location, and video. Earlier works often focused on unimodal pipelines (e.g., only text or only images), which delay decision-making. Advances such as Word2Vec, CNNs, and YOLO, as well as topic modeling techniques like LDA, have allowed systems to analyze and interpret multiple data sources in parallel.\n",
    "\n",
    "Multimodal approaches are now widely used in domains such as autonomous driving, medical diagnosis, and increasingly, in emergency response through tools like CrisisMMD and MediaEval datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f496bfd",
   "metadata": {},
   "source": [
    "## Learnings from This Work\n",
    "- Multimodal integration offers faster and context-rich insights.\n",
    "- Text classification using NLP tools such as Bag-of-Words and Word2Vec enhances situational understanding.\n",
    "- Object detection using CNNs helps in analyzing infrastructure damage from images.\n",
    "- Topic modeling (e.g., LDA) can determine the disaster stage (pre-, during, or post-disaster)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354a56e",
   "metadata": {},
   "source": [
    "## Code Snippets and Demonstration\n",
    "Here’s a small demo of text preprocessing and vectorization using Word2Vec for disaster tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Example tweets\n",
    "tweets = [\n",
    "    \"Earthquake destroyed my house. Need help!\",\n",
    "    \"Floods in Mumbai again. Streets are underwater.\",\n",
    "    \"Rescue teams are helping victims in Assam.\",\n",
    "    \"Bridge collapsed due to heavy rain in Kerala.\"\n",
    "]\n",
    "\n",
    "# Tokenization\n",
    "tokenized = [word_tokenize(tweet.lower()) for tweet in tweets]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized, vector_size=50, window=2, min_count=1, workers=2)\n",
    "\n",
    "# Vector for a sample word\n",
    "print(model.wv['earthquake'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9d128",
   "metadata": {},
   "source": [
    "### Image Analysis (Conceptual)\n",
    "For image data, pre-trained CNNs (e.g., VGG, ResNet) or YOLO can be used to identify damaged structures or crowded zones during disasters. Example pipeline:\n",
    "\n",
    "```python\n",
    "# Pseudocode (no actual image files here)\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Assume we have a disaster image\n",
    "img = Image.open('disaster_scene.jpg')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "img_t = transform(img).unsqueeze(0)\n",
    "\n",
    "output = model(img_t)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14174109",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "**What surprised me?**\n",
    "- The diversity and richness of social media data. One post can have location, timestamp, image, and meaningful text.\n",
    "- Combining simple NLP models and basic CNNs still yields informative outputs.\n",
    "\n",
    "**Scope for improvement:**\n",
    "- Incorporating real-time data pipelines.\n",
    "- Adding video summarization and crowd-sourced validation.\n",
    "- Integrating with IoT and drone-based surveillance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff591a7",
   "metadata": {},
   "source": [
    "## References\n",
    "- Mikolov et al., 2013: *Efficient Estimation of Word Representations in Vector Space (Word2Vec)*\n",
    "- YOLO: *You Only Look Once: Unified, Real-Time Object Detection*\n",
    "- Blei et al., 2003: *Latent Dirichlet Allocation*\n",
    "- CrisisMMD Dataset\n",
    "- Gensim, Torchvision, NLTK"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}